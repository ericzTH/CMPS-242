{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import os,re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Couldn't be more proud of @HillaryClinton. Her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This election is too important to sit out. Go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once again, we will have a government of, by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On National #VoterRegistrationDay, make sure y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great afternoon in Little Havana with Hispanic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It's #NationalVoterRegistrationDay. Celebrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I love this country.\\rIÛªm proud of this cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"What kind of a person would want to root for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"I donÛªt think that any family should have t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Join Hillary live in NC for her first rally si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Couldn't be more proud of @HillaryClinton. Her...\n",
       "1  This election is too important to sit out. Go ...\n",
       "2  Once again, we will have a government of, by a...\n",
       "3  On National #VoterRegistrationDay, make sure y...\n",
       "4  Great afternoon in Little Havana with Hispanic...\n",
       "5  It's #NationalVoterRegistrationDay. Celebrate ...\n",
       "6  \"I love this country.\\rIÛªm proud of this cou...\n",
       "7  \"What kind of a person would want to root for ...\n",
       "8  \"I donÛªt think that any family should have t...\n",
       "9  Join Hillary live in NC for her first rally si..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test_final.csv\",encoding = \"ISO-8859-1\", header = None)\n",
    "print(len(test_data))\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    The question in this election: Who can put the...\n",
       "1    Last night, Donald Trump said not paying taxes...\n",
       "2    If we stand together, there's nothing we can't...\n",
       "3    Both candidates were asked about how they'd co...\n",
       "4    Join me for a 3pm rally - tomorrow at the Mid-...\n",
       "5    When Donald Trump goes low...register to vote:...\n",
       "6    3) Has Trump offered a single proposal to redu...\n",
       "7    The election is just weeks away. Check if you'...\n",
       "8    Hillary Clinton's Campaign Continues To Make F...\n",
       "9    'CNBC, Time magazine online polls say Donald T...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\",header = None)\n",
    "print(len(train_data))\n",
    "train_data.describe()\n",
    "train_data[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train = pd.read_csv(\"labels_train_tweets.csv\",header = None)\n",
    "labels_train[0] = labels_train[0].map({'HC':1,'DT':0})\n",
    "#Hillary = 1 , DT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  0\n",
       "5  1\n",
       "6  1\n",
       "7  1\n",
       "8  0\n",
       "9  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The actual vocab size was around 12k, but using a larger number \n",
    "#reduces the probability of collisions from the hash function.\n",
    "vocab_size = 20000\n",
    "encoded_tweets = [one_hot(d, vocab_size) for d in train_data[0]]\n",
    "encoded_test = [one_hot(d, vocab_size) for d in test_data[0]]\n",
    "tweet_lengths = [len(t) for t in encoded_tweets]\n",
    "test_lengths = [len(t) for t in encoded_test]\n",
    "max_length = 0\n",
    "for t in encoded_tweets:\n",
    "    if len(t) > max_length:\n",
    "        max_length = len(t)\n",
    "        \n",
    "for t in encoded_test:\n",
    "    if len(t) > max_length:\n",
    "        max_length = len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels_train\n",
    "padded_tweets\n",
    "tweet_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleDataIterator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.size = len(self.df)\n",
    "        self.epochs = 0\n",
    "        self.shuffle()\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.cursor = 0\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n-1 > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "        return res['data'], res['labels'], res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " 0    [12658, 2137, 5316, 3923, 14360, 15733, 7636, ...\n",
      "1    [14242, 10537, 5928, 15282, 19464, 15733, 3657...\n",
      "2    [11156, 1197, 13653, 1561, 11559, 11511, 2491,...\n",
      "Name: data, dtype: object\n",
      "\n",
      "Target values\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Sequence lengths\n",
      " 0    24\n",
      "1    17\n",
      "2    23\n",
      "Name: length, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train_dic={}\n",
    "train_dic[\"data\"] = encoded_tweets\n",
    "train_dic[\"labels\"] = labels_train[0].ravel().tolist()\n",
    "train_dic[\"length\"] = tweet_lengths\n",
    "train_len = len(train_data)\n",
    "test_len = len(test_data)\n",
    "\n",
    "train = pd.DataFrame.from_dict(data=train_dic, orient='columns', dtype=None)\n",
    "\n",
    "\n",
    "test_dic={}\n",
    "test_dic[\"data\"] = encoded_test\n",
    "test_dic[\"length\"] = test_lengths\n",
    "test = pd.DataFrame.from_dict(data=test_dic, orient='columns', dtype=None)\n",
    "\n",
    "test_input = test.values\n",
    "\n",
    "data = SimpleDataIterator(train)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n', d[0], end='\\n\\n')\n",
    "print('Target values\\n', d[1], end='\\n\\n')\n",
    "print('Sequence lengths\\n', d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PaddedDataIterator(SimpleDataIterator):\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "\n",
    "        # Pad sequences with 0s so they are all the same length\n",
    "        maxlen = max(res['length'])\n",
    "        x = np.zeros([n, maxlen], dtype=np.int32)\n",
    "        for i, x_i in enumerate(x):\n",
    "            x_i[:res['length'].values[i]] = res['data'].values[i]\n",
    "\n",
    "        return x, res['labels'], res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " [[ 2137  3206 15282 12343  1448  5309  1448 10726  3133 12863 13231 11511\n",
      "   3037    59 17799     0     0     0     0     0     0     0]\n",
      " [11185 17878 14315  4154 10726  2882  2338 15282 10636 15733 10006   772\n",
      "   5754 14360 15282  6206 12712  1414  1491  5776 18197   152]\n",
      " [ 5684 15099 18191 16208  5903  9083 16697 15733  7045 13794  2714 16527\n",
      "  12295 12702 16697 17807  1491  5776 18197 14475     0     0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = PaddedDataIterator(train)\n",
    "train_data = PaddedDataIterator(test)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n', d[0], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "def build_graph(\n",
    "    vocab_size = vocab_size,\n",
    "    state_size = 64,\n",
    "    batch_size = 189,\n",
    "    num_classes = 2):\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "    y = tf.placeholder(tf.int32, [batch_size])\n",
    "    keep_prob = tf.placeholder_with_default(1.0, [])\n",
    "\n",
    "    # Embedding layer\n",
    "    embeddings = tf.get_variable('embedding_matrix', [vocab_size, state_size])\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(state_size)\n",
    "    init_state = tf.get_variable('init_state', [1, state_size],\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "    init_state = tf.tile(init_state, [batch_size, 1])\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen,\n",
    "                                                 initial_state=init_state)\n",
    "\n",
    "    # Add dropout, as the model otherwise quickly overfits\n",
    "    rnn_outputs = tf.nn.dropout(rnn_outputs, keep_prob)\n",
    "\n",
    "    \"\"\"\n",
    "    Obtain the last relevant output. The best approach in the future will be to use:\n",
    "\n",
    "        last_rnn_output = tf.gather_nd(rnn_outputs, tf.pack([tf.range(batch_size), seqlen-1], axis=1))\n",
    "\n",
    "    which is the Tensorflow equivalent of numpy's rnn_outputs[range(30), seqlen-1, :], but the\n",
    "    gradient for this op has not been implemented as of this writing.\n",
    "\n",
    "    The below solution works, but throws a UserWarning re: the gradient.\n",
    "    \"\"\"\n",
    "    idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n",
    "    last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n",
    "\n",
    "    # Softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output, W) + b\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    return {\n",
    "        'x': x,\n",
    "        'seqlen': seqlen,\n",
    "        'y': y,\n",
    "        'dropout': keep_prob,\n",
    "        'loss': loss,\n",
    "        'ts': train_step,\n",
    "        'preds': preds,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def train_graph(graph, sess, batch_size = 189, num_epochs = 13, iterator = PaddedDataIterator):\n",
    "    \n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tr = iterator(train)\n",
    "    te = iterator(test)\n",
    "\n",
    "    step, accuracy = 0, 0\n",
    "    tr_losses, te_losses = [], []\n",
    "    current_epoch = 0\n",
    "    while current_epoch < num_epochs:\n",
    "        step += 1\n",
    "        batch = tr.next_batch(batch_size)\n",
    "        feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['dropout']: 0.6}\n",
    "        accuracy_, _ = sess.run([g['accuracy'], g['ts']], feed_dict=feed)\n",
    "        accuracy += accuracy_\n",
    "\n",
    "        if tr.epochs > current_epoch:\n",
    "            current_epoch += 1\n",
    "            tr_losses.append(accuracy / step)\n",
    "            step, accuracy = 0, 0\n",
    "\n",
    "            #eval test set\n",
    "            \"\"\" te_epoch = te.epochs\n",
    "            while te.epochs == te_epoch:\n",
    "                step += 1\n",
    "                batch = te.next_batch(batch_size)\n",
    "                feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2]}\n",
    "                accuracy_ = sess.run([g['accuracy'],g['loss']], feed_dict=feed)[0]\n",
    "                accuracy += accuracy_\n",
    "\n",
    "            te_losses.append(accuracy / step)\"\"\"\n",
    "            step, accuracy = 0,0\n",
    "            print(\"Accuracy after epoch\", current_epoch, \" - tr:\", tr_losses[-1])#, \"- te:\", te_losses[-1])\n",
    "    return tr_losses#, te_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 1  - tr: 0.569800576338\n",
      "Accuracy after epoch 2  - tr: 0.689523806572\n",
      "Accuracy after epoch 3  - tr: 0.754708986282\n",
      "Accuracy after epoch 4  - tr: 0.828783071041\n",
      "Accuracy after epoch 5  - tr: 0.872380964756\n",
      "Accuracy after epoch 6  - tr: 0.903068795204\n",
      "Accuracy after epoch 7  - tr: 0.913227515221\n",
      "Accuracy after epoch 8  - tr: 0.926984131336\n",
      "Accuracy after epoch 9  - tr: 0.946031751633\n",
      "Accuracy after epoch 10  - tr: 0.959365079403\n",
      "Accuracy after epoch 11  - tr: 0.96931217432\n",
      "Accuracy after epoch 12  - tr: 0.97417989254\n",
      "Accuracy after epoch 13  - tr: 0.981587300301\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()\n",
    "#tr_losses, te_losses = train_graph(g)\n",
    "sess = tf.Session()\n",
    "tr_losses = train_graph(g, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  3.06655624e-04,   9.99693394e-01],\n",
      "       [  5.98663057e-04,   9.99401331e-01],\n",
      "       [  9.98819172e-01,   1.18075195e-03],\n",
      "       [  4.18661982e-02,   9.58133817e-01],\n",
      "       [  9.95761812e-01,   4.23823949e-03],\n",
      "       [  4.49914439e-03,   9.95500863e-01],\n",
      "       [  1.96282417e-01,   8.03717613e-01],\n",
      "       [  1.43793484e-04,   9.99856234e-01],\n",
      "       [  5.25198237e-04,   9.99474823e-01],\n",
      "       [  5.71503460e-01,   4.28496510e-01],\n",
      "       [  4.86638486e-01,   5.13361514e-01],\n",
      "       [  2.62235343e-01,   7.37764597e-01],\n",
      "       [  1.78329775e-03,   9.98216689e-01],\n",
      "       [  5.72474487e-02,   9.42752481e-01],\n",
      "       [  7.48773575e-01,   2.51226336e-01],\n",
      "       [  7.62694597e-01,   2.37305343e-01],\n",
      "       [  6.96491301e-01,   3.03508699e-01],\n",
      "       [  9.98696983e-01,   1.30300852e-03],\n",
      "       [  9.63049307e-02,   9.03695047e-01],\n",
      "       [  9.65713799e-01,   3.42861861e-02],\n",
      "       [  9.99804676e-01,   1.95357963e-04],\n",
      "       [  2.37465114e-03,   9.97625411e-01],\n",
      "       [  5.02340198e-01,   4.97659832e-01],\n",
      "       [  7.05338597e-01,   2.94661433e-01],\n",
      "       [  1.28479898e-02,   9.87152040e-01],\n",
      "       [  7.46187717e-02,   9.25381243e-01],\n",
      "       [  9.78372037e-01,   2.16278899e-02],\n",
      "       [  7.75459111e-02,   9.22454059e-01],\n",
      "       [  1.91783311e-03,   9.98082161e-01],\n",
      "       [  9.51418459e-01,   4.85815220e-02],\n",
      "       [  6.26078010e-01,   3.73921990e-01],\n",
      "       [  8.60819995e-01,   1.39180049e-01],\n",
      "       [  3.91314030e-02,   9.60868657e-01],\n",
      "       [  5.03682435e-01,   4.96317565e-01],\n",
      "       [  6.50641501e-01,   3.49358499e-01],\n",
      "       [  6.78857028e-01,   3.21143001e-01],\n",
      "       [  4.85217534e-02,   9.51478243e-01],\n",
      "       [  1.07198492e-01,   8.92801523e-01],\n",
      "       [  4.80062097e-01,   5.19937932e-01],\n",
      "       [  2.95127064e-01,   7.04872906e-01],\n",
      "       [  5.36069892e-05,   9.99946356e-01],\n",
      "       [  5.65215588e-01,   4.34784383e-01],\n",
      "       [  1.38930290e-03,   9.98610616e-01],\n",
      "       [  2.00742739e-03,   9.97992635e-01],\n",
      "       [  4.98459697e-01,   5.01540244e-01],\n",
      "       [  1.16098031e-01,   8.83901954e-01],\n",
      "       [  2.82956332e-01,   7.17043698e-01],\n",
      "       [  9.95090365e-01,   4.90965787e-03],\n",
      "       [  1.83789954e-02,   9.81620967e-01],\n",
      "       [  2.32230942e-03,   9.97677743e-01],\n",
      "       [  7.71394134e-01,   2.28605896e-01],\n",
      "       [  5.08617163e-01,   4.91382748e-01],\n",
      "       [  3.43229086e-03,   9.96567726e-01],\n",
      "       [  3.02138627e-01,   6.97861373e-01],\n",
      "       [  1.54996514e-01,   8.45003486e-01],\n",
      "       [  9.99886751e-01,   1.13295078e-04],\n",
      "       [  2.27190997e-03,   9.97728050e-01],\n",
      "       [  9.51252354e-04,   9.99048769e-01],\n",
      "       [  8.68571550e-02,   9.13142860e-01],\n",
      "       [  9.98686731e-01,   1.31322211e-03],\n",
      "       [  1.10582274e-04,   9.99889374e-01],\n",
      "       [  9.73985717e-02,   9.02601421e-01],\n",
      "       [  7.20334470e-01,   2.79665589e-01],\n",
      "       [  3.23800266e-01,   6.76199734e-01],\n",
      "       [  8.82387348e-03,   9.91176128e-01],\n",
      "       [  2.94060301e-04,   9.99705970e-01],\n",
      "       [  3.71874273e-02,   9.62812603e-01],\n",
      "       [  1.72559619e-02,   9.82744038e-01],\n",
      "       [  1.39988795e-01,   8.60011220e-01],\n",
      "       [  1.55768963e-02,   9.84423101e-01],\n",
      "       [  9.92505729e-01,   7.49429455e-03],\n",
      "       [  1.66968197e-01,   8.33031833e-01],\n",
      "       [  4.16625828e-01,   5.83374202e-01],\n",
      "       [  3.85329104e-03,   9.96146679e-01],\n",
      "       [  3.87996510e-02,   9.61200356e-01],\n",
      "       [  1.36454776e-03,   9.98635471e-01],\n",
      "       [  2.95380334e-04,   9.99704540e-01],\n",
      "       [  5.79565589e-04,   9.99420404e-01],\n",
      "       [  1.62640808e-03,   9.98373508e-01],\n",
      "       [  7.95610977e-05,   9.99920487e-01],\n",
      "       [  1.38832501e-03,   9.98611689e-01],\n",
      "       [  1.01324534e-02,   9.89867568e-01],\n",
      "       [  5.90918935e-05,   9.99940872e-01],\n",
      "       [  5.68055034e-01,   4.31944996e-01],\n",
      "       [  9.91990030e-01,   8.00996646e-03],\n",
      "       [  5.96877933e-02,   9.40312207e-01],\n",
      "       [  9.99707758e-01,   2.92244484e-04],\n",
      "       [  9.99772847e-01,   2.27131270e-04],\n",
      "       [  3.22568491e-02,   9.67743218e-01],\n",
      "       [  5.69422305e-01,   4.30577695e-01],\n",
      "       [  5.06417565e-02,   9.49358225e-01],\n",
      "       [  7.28798425e-03,   9.92712021e-01],\n",
      "       [  6.28081290e-03,   9.93719220e-01],\n",
      "       [  9.80374098e-01,   1.96259543e-02],\n",
      "       [  9.78251338e-01,   2.17486639e-02],\n",
      "       [  3.97310793e-01,   6.02689207e-01],\n",
      "       [  4.30002883e-02,   9.56999719e-01],\n",
      "       [  1.41286952e-02,   9.85871255e-01],\n",
      "       [  2.26278964e-04,   9.99773681e-01],\n",
      "       [  5.59131941e-03,   9.94408667e-01],\n",
      "       [  4.60043475e-02,   9.53995705e-01],\n",
      "       [  1.08335388e-03,   9.98916626e-01],\n",
      "       [  2.54755504e-02,   9.74524438e-01],\n",
      "       [  1.54914549e-02,   9.84508514e-01],\n",
      "       [  5.55367805e-02,   9.44463193e-01],\n",
      "       [  9.97398853e-01,   2.60112341e-03],\n",
      "       [  3.30872746e-04,   9.99669194e-01],\n",
      "       [  2.24558655e-02,   9.77544129e-01],\n",
      "       [  5.15458081e-03,   9.94845390e-01],\n",
      "       [  4.85103251e-03,   9.95148957e-01],\n",
      "       [  1.77024122e-04,   9.99823034e-01],\n",
      "       [  3.61310580e-04,   9.99638677e-01],\n",
      "       [  7.81858206e-01,   2.18141779e-01],\n",
      "       [  4.97852594e-01,   5.02147377e-01],\n",
      "       [  9.99619961e-01,   3.79985926e-04],\n",
      "       [  3.03666282e-04,   9.99696374e-01],\n",
      "       [  1.31711036e-01,   8.68288934e-01],\n",
      "       [  9.99215722e-01,   7.84289965e-04],\n",
      "       [  2.53637079e-02,   9.74636316e-01],\n",
      "       [  4.43754652e-05,   9.99955654e-01],\n",
      "       [  2.78726909e-02,   9.72127318e-01],\n",
      "       [  8.59004632e-02,   9.14099514e-01],\n",
      "       [  2.68177129e-04,   9.99731839e-01],\n",
      "       [  4.63569624e-04,   9.99536395e-01],\n",
      "       [  5.76681912e-01,   4.23318058e-01],\n",
      "       [  3.02521978e-04,   9.99697447e-01],\n",
      "       [  1.89769808e-02,   9.81023014e-01],\n",
      "       [  6.09620363e-02,   9.39037919e-01],\n",
      "       [  2.27123462e-02,   9.77287650e-01],\n",
      "       [  4.10831394e-03,   9.95891690e-01],\n",
      "       [  2.87266244e-04,   9.99712765e-01],\n",
      "       [  1.19909905e-02,   9.88008976e-01],\n",
      "       [  1.64585782e-03,   9.98354197e-01],\n",
      "       [  8.33645317e-05,   9.99916673e-01],\n",
      "       [  2.30596084e-02,   9.76940393e-01],\n",
      "       [  4.30328697e-01,   5.69671392e-01],\n",
      "       [  8.87221396e-01,   1.12778619e-01],\n",
      "       [  3.29253008e-03,   9.96707439e-01],\n",
      "       [  3.10726638e-04,   9.99689341e-01],\n",
      "       [  1.58915087e-03,   9.98410821e-01],\n",
      "       [  2.89565022e-03,   9.97104347e-01],\n",
      "       [  3.37950528e-01,   6.62049472e-01],\n",
      "       [  7.20307138e-03,   9.92796957e-01],\n",
      "       [  7.75369525e-01,   2.24630535e-01],\n",
      "       [  2.98925588e-04,   9.99701083e-01],\n",
      "       [  9.99645472e-01,   3.54480057e-04],\n",
      "       [  2.66921461e-01,   7.33078599e-01],\n",
      "       [  3.75579781e-04,   9.99624372e-01],\n",
      "       [  2.03829911e-02,   9.79616940e-01],\n",
      "       [  6.86920285e-02,   9.31307912e-01],\n",
      "       [  2.96096521e-04,   9.99703825e-01],\n",
      "       [  7.00273216e-01,   2.99726754e-01],\n",
      "       [  3.28367605e-04,   9.99671698e-01],\n",
      "       [  8.90873551e-01,   1.09126449e-01],\n",
      "       [  4.50698519e-03,   9.95493054e-01],\n",
      "       [  3.73364210e-01,   6.26635790e-01],\n",
      "       [  1.98901491e-03,   9.98011053e-01],\n",
      "       [  7.88975134e-02,   9.21102464e-01],\n",
      "       [  6.26403431e-04,   9.99373615e-01],\n",
      "       [  4.99865264e-01,   5.00134826e-01],\n",
      "       [  8.44086893e-03,   9.91559148e-01],\n",
      "       [  5.81880748e-01,   4.18119311e-01],\n",
      "       [  3.97321419e-05,   9.99960303e-01],\n",
      "       [  9.95576262e-01,   4.42373240e-03],\n",
      "       [  3.55281332e-03,   9.96447265e-01],\n",
      "       [  8.27623880e-05,   9.99917269e-01],\n",
      "       [  1.84872144e-04,   9.99815166e-01],\n",
      "       [  9.98720407e-01,   1.27965433e-03],\n",
      "       [  9.98072863e-01,   1.92707486e-03],\n",
      "       [  5.87829351e-02,   9.41217005e-01],\n",
      "       [  8.41925144e-02,   9.15807486e-01],\n",
      "       [  5.80161926e-04,   9.99419808e-01],\n",
      "       [  2.41962541e-03,   9.97580290e-01],\n",
      "       [  5.90339478e-04,   9.99409676e-01],\n",
      "       [  7.61113942e-01,   2.38886073e-01],\n",
      "       [  5.94742363e-04,   9.99405265e-01],\n",
      "       [  2.02465326e-01,   7.97534645e-01],\n",
      "       [  7.58280884e-03,   9.92417216e-01],\n",
      "       [  9.94811893e-01,   5.18815964e-03],\n",
      "       [  9.97006118e-01,   2.99389916e-03],\n",
      "       [  7.41887018e-02,   9.25811350e-01],\n",
      "       [  9.97282028e-01,   2.71800463e-03],\n",
      "       [  9.99958038e-01,   4.19089411e-05],\n",
      "       [  4.87722874e-01,   5.12277067e-01],\n",
      "       [  3.40286970e-01,   6.59713089e-01],\n",
      "       [  9.98991549e-01,   1.00845634e-03],\n",
      "       [  2.18520705e-02,   9.78147864e-01],\n",
      "       [  3.08294897e-03,   9.96917009e-01],\n",
      "       [  2.41860952e-02,   9.75813925e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_input = test\n",
    "test_input['data'] = test['data'].apply(lambda x : np.array(x))\n",
    "test_input['length'] = test_input['length'].apply(lambda x : np.array(x))\n",
    "maxlen = max(test_input['length'])\n",
    "x = np.zeros([len(test_input), maxlen], dtype=np.int32)\n",
    "for i, x_i in enumerate(x):\n",
    "    x_i[:test_input['length'].values[i]] = test_input['data'].values[i]\n",
    "\n",
    "results = []\n",
    "import math\n",
    "for i in range(math.floor(len(x)/189)):\n",
    "    data_bit = x[i*189:(i+1)*189]\n",
    "    len_bit = test_input['length'][i*189:(i+1)*189]\n",
    "    results.append(sess.run([g[\"preds\"]], feed_dict={g['x']: data_bit, g['seqlen'] : len_bit}))\n",
    "print(results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0391314   0.96086866]\n"
     ]
    }
   ],
   "source": [
    "print(results[0][0][32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"id,realDonaldTrump,HillaryClinton\\n\")\n",
    "    #batch of 189\n",
    "    i = 0\n",
    "    print (len(results))\n",
    "    for n in range(len(results)):\n",
    "        print (len(results[n][0]))\n",
    "        for y in range(len(results[n][0])):\n",
    "            f.write(\"{},{:06f},{:06f}\\n\".format(i, results[n][0][y][0],results[n][0][y][1]))\n",
    "            i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
