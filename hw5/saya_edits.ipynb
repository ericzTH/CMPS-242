{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import os,re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>Couldn't be more proud of @HillaryClinton. Her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>This election is too important to sit out. Go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>Once again, we will have a government of, by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>On National #VoterRegistrationDay, make sure y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>Great afternoon in Little Havana with Hispanic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>It's #NationalVoterRegistrationDay. Celebrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>\"I love this country.\\nI’m proud of this count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>\"What kind of a person would want to root for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>\"I don’t think that any family should have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>Join Hillary live in NC for her first rally si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  handle                                              tweet\n",
       "0   none  Couldn't be more proud of @HillaryClinton. Her...\n",
       "1   none  This election is too important to sit out. Go ...\n",
       "2   none  Once again, we will have a government of, by a...\n",
       "3   none  On National #VoterRegistrationDay, make sure y...\n",
       "4   none  Great afternoon in Little Havana with Hispanic...\n",
       "5   none  It's #NationalVoterRegistrationDay. Celebrate ...\n",
       "6   none  \"I love this country.\\nI’m proud of this count...\n",
       "7   none  \"What kind of a person would want to root for ...\n",
       "8   none  \"I don’t think that any family should have to ...\n",
       "9   none  Join Hillary live in NC for her first rally si..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "print(len(test_data))\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    The question in this election: Who can put the...\n",
       "1    Last night, Donald Trump said not paying taxes...\n",
       "2    If we stand together, there's nothing we can't...\n",
       "3    Both candidates were asked about how they'd co...\n",
       "4    Join me for a 3pm rally - tomorrow at the Mid-...\n",
       "5    When Donald Trump goes low...register to vote:...\n",
       "6    3) Has Trump offered a single proposal to redu...\n",
       "7    The election is just weeks away. Check if you'...\n",
       "8    Hillary Clinton's Campaign Continues To Make F...\n",
       "9    'CNBC, Time magazine online polls say Donald T...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\",header = None)\n",
    "print(len(train_data))\n",
    "train_data.describe()\n",
    "train_data[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Couldn't be more proud of @HillaryClinton. Her...\n",
       "1    This election is too important to sit out. Go ...\n",
       "2    Once again, we will have a government of, by a...\n",
       "3    On National #VoterRegistrationDay, make sure y...\n",
       "4    Great afternoon in Little Havana with Hispanic...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_data[0].copy()\n",
    "test_text = test_data['tweet'].copy()\n",
    "labels_train = pd.read_csv(\"labels_train_tweets.csv\",header = None)\n",
    "labels_train[0] = labels_train[0].map({'HC':1,'DT':0})\n",
    "test_text.head()\n",
    "#Hillary = 1 , DT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  0\n",
       "5  1\n",
       "6  1\n",
       "7  1\n",
       "8  0\n",
       "9  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The actual vocab size was around 12k, but using a larger number \n",
    "#reduces the probability of collisions from the hash function.\n",
    "vocab_size = 10 #000\n",
    "encoded_tweets = [one_hot(d, vocab_size) for d in train_data[0]]\n",
    "encoded_test = [one_hot(d, vocab_size) for d in test_text]\n",
    "tweet_lengths = [len(t) for t in encoded_tweets]\n",
    "test_lengths = [len(t) for t in encoded_test]\n",
    "max_length = 0\n",
    "for t in encoded_tweets:\n",
    "    if len(t) > max_length:\n",
    "        max_length = len(t)\n",
    "        \n",
    "for t in encoded_test:\n",
    "    if len(t) > max_length:\n",
    "        max_length = len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels_train\n",
    "padded_tweets\n",
    "tweet_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataIterator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.size = len(self.df)\n",
    "        self.epochs = 0\n",
    "        self.shuffle()\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.cursor = 0\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n-1 > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "        return res['data'], res['labels'], res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " 0    [2, 7, 3, 1, 3, 2, 4, 5, 9, 9, 2, 6, 1, 1, 7, ...\n",
      "1                                   [1, 9, 6, 9, 6, 6]\n",
      "2    [3, 3, 2, 1, 9, 4, 2, 5, 5, 1, 5, 4, 9, 8, 4, ...\n",
      "Name: data, dtype: object\n",
      "\n",
      "Target values\n",
      " 0    1\n",
      "1    1\n",
      "2    0\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Sequence lengths\n",
      " 0    21\n",
      "1     6\n",
      "2    19\n",
      "Name: length, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train_dic={}\n",
    "train_dic[\"data\"] = encoded_tweets\n",
    "train_dic[\"labels\"] = labels_train[0].ravel().tolist()\n",
    "train_dic[\"length\"] = tweet_lengths\n",
    "train_len = len(train_data)\n",
    "test_len = len(test_data)\n",
    "\n",
    "train = pd.DataFrame.from_dict(data=train_dic, orient='columns', dtype=None)\n",
    "\n",
    "\n",
    "test_dic={}\n",
    "test_dic[\"data\"] = encoded_test\n",
    "test_dic[\"length\"] = test_lengths\n",
    "test = pd.DataFrame.from_dict(data=test_dic, orient='columns', dtype=None)\n",
    "\n",
    "test_input = test.values\n",
    "\n",
    "data = SimpleDataIterator(train)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n', d[0], end='\\n\\n')\n",
    "print('Target values\\n', d[1], end='\\n\\n')\n",
    "print('Sequence lengths\\n', d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedDataIterator(SimpleDataIterator):\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "\n",
    "        # Pad sequences with 0s so they are all the same length\n",
    "        maxlen = max(res['length'])\n",
    "        x = np.zeros([n, maxlen], dtype=np.int32)\n",
    "        for i, x_i in enumerate(x):\n",
    "            x_i[:res['length'].values[i]] = res['data'].values[i]\n",
    "\n",
    "        return x, res['labels'], res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " [[3 3 7 8 5 3 8 3 9 9 8 9 8 9 9 1 5 7 4 3 2 2]\n",
      " [8 3 5 3 9 1 1 4 4 9 8 9 1 1 9 3 3 9 4 3 2 5]\n",
      " [9 3 5 5 7 3 3 8 7 8 4 3 2 8 0 0 0 0 0 0 0 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = PaddedDataIterator(train)\n",
    "train_data = PaddedDataIterator(test)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n', d[0], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "def build_graph(\n",
    "    vocab_size = vocab_size,\n",
    "    state_size = 24,\n",
    "    batch_size = 189,\n",
    "    num_classes = 2):\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "    y = tf.placeholder(tf.int32, [batch_size])\n",
    "    keep_prob = tf.placeholder_with_default(1.0, [])\n",
    "\n",
    "    # Embedding layer\n",
    "    embeddings = tf.get_variable('embedding_matrix', [vocab_size, state_size])\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(state_size,forget_bias = 1)\n",
    "    #cell = tf.contrib.rnn.LSTMCell(state_size,forget_bias = 1)\n",
    "    init_state = tf.get_variable('init_state', [1, state_size],\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "    init_state = tf.tile(init_state, [batch_size, 1])\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs,dtype=tf.float32)#, sequence_length=seqlen,initial_state=init_state)\n",
    "\n",
    "    # Add dropout, as the model otherwise quickly overfits\n",
    "    rnn_outputs = tf.nn.dropout(rnn_outputs, keep_prob)\n",
    "\n",
    "    \"\"\"\n",
    "    Obtain the last relevant output. The best approach in the future will be to use:\n",
    "\n",
    "        last_rnn_output = tf.gather_nd(rnn_outputs, tf.pack([tf.range(batch_size), seqlen-1], axis=1))\n",
    "\n",
    "    which is the Tensorflow equivalent of numpy's rnn_outputs[range(30), seqlen-1, :], but the\n",
    "    gradient for this op has not been implemented as of this writing.\n",
    "\n",
    "    The below solution works, but throws a UserWarning re: the gradient.\n",
    "    \"\"\"\n",
    "    idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n",
    "    last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n",
    "\n",
    "    # Softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output, W) + b\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    return {\n",
    "        'x': x,\n",
    "        'seqlen': seqlen,\n",
    "        'y': y,\n",
    "        'dropout': keep_prob,\n",
    "        'loss': loss,\n",
    "        'ts': train_step,\n",
    "        'preds': preds,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def train_graph(graph, sess, batch_size = 189, num_epochs = 30000, iterator = PaddedDataIterator):\n",
    "    \n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tr = iterator(train)\n",
    "    te = iterator(test)\n",
    "\n",
    "    step, accuracy = 0, 0\n",
    "    tr_losses, te_losses = [], []\n",
    "    current_epoch = 0\n",
    "    while current_epoch < num_epochs:\n",
    "        step += 1\n",
    "        batch = tr.next_batch(batch_size)\n",
    "        feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2], g['dropout']: 0.6}\n",
    "        accuracy_, _ = sess.run([g['accuracy'], g['ts']], feed_dict=feed)\n",
    "        accuracy += accuracy_\n",
    "\n",
    "        if tr.epochs > current_epoch:\n",
    "            current_epoch += 1\n",
    "            tr_losses.append(accuracy / step)\n",
    "            step, accuracy = 0, 0\n",
    "            if step >1 and accuracy/step >= 0.98:\n",
    "                break;\n",
    "            #eval test set\n",
    "            \"\"\" te_epoch = te.epochs\n",
    "            while te.epochs == te_epoch:\n",
    "                step += 1\n",
    "                batch = te.next_batch(batch_size)\n",
    "                feed = {g['x']: batch[0], g['y']: batch[1], g['seqlen']: batch[2]}\n",
    "                accuracy_ = sess.run([g['accuracy'],g['loss']], feed_dict=feed)[0]\n",
    "                accuracy += accuracy_\n",
    "\n",
    "            te_losses.append(accuracy / step)\"\"\"\n",
    "            step, accuracy = 0,0\n",
    "            if current_epoch%100 == 0:\n",
    "                print(\"Accuracy after epoch\", current_epoch, \" - tr:\", tr_losses[-1])#, \"- te:\", te_losses[-1])\n",
    "    return tr_losses#, te_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 100  - tr: 0.695026450157\n",
      "Accuracy after epoch 200  - tr: 0.70497354269\n",
      "Accuracy after epoch 300  - tr: 0.718518507481\n",
      "Accuracy after epoch 400  - tr: 0.729100530148\n",
      "Accuracy after epoch 500  - tr: 0.732275128365\n",
      "Accuracy after epoch 600  - tr: 0.742857139111\n",
      "Accuracy after epoch 700  - tr: 0.746666657925\n",
      "Accuracy after epoch 800  - tr: 0.743280417919\n",
      "Accuracy after epoch 900  - tr: 0.753862428665\n",
      "Accuracy after epoch 1000  - tr: 0.758518507481\n",
      "Accuracy after epoch 1100  - tr: 0.766772484779\n",
      "Accuracy after epoch 1200  - tr: 0.761693117619\n",
      "Accuracy after epoch 1300  - tr: 0.772910044193\n",
      "Accuracy after epoch 1400  - tr: 0.77777777195\n",
      "Accuracy after epoch 1500  - tr: 0.776296288967\n",
      "Accuracy after epoch 1600  - tr: 0.772063493729\n",
      "Accuracy after epoch 1700  - tr: 0.771216924191\n",
      "Accuracy after epoch 1800  - tr: 0.782222218513\n",
      "Accuracy after epoch 1900  - tr: 0.78730158329\n",
      "Accuracy after epoch 2000  - tr: 0.791111104488\n",
      "Accuracy after epoch 2100  - tr: 0.78962962389\n",
      "Accuracy after epoch 2200  - tr: 0.797460310459\n",
      "Accuracy after epoch 2300  - tr: 0.801058194637\n",
      "Accuracy after epoch 2400  - tr: 0.793650789261\n",
      "Accuracy after epoch 2500  - tr: 0.794920630455\n",
      "Accuracy after epoch 2600  - tr: 0.798306872845\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()\n",
    "#tr_losses, te_losses = train_graph(g)\n",
    "sess = tf.Session()\n",
    "tr_losses = train_graph(g, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "x = [x for x in range(len(tr_losses))]\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot(x,tr_losses, label = \"Training Step vs Training Accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"best_LSTM.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test\n",
    "test_input['data'] = test['data'].apply(lambda x : np.array(x))\n",
    "test_input['length'] = test_input['length'].apply(lambda x : np.array(x))\n",
    "maxlen = max(test_input['length'])\n",
    "x = np.zeros([len(test_input), maxlen], dtype=np.int32)\n",
    "for i, x_i in enumerate(x):\n",
    "    x_i[:test_input['length'].values[i]] = test_input['data'].values[i]\n",
    "\n",
    "results = []\n",
    "import math\n",
    "for i in range(math.floor(len(x)/189)):\n",
    "    data_bit = x[i*189:(i+1)*189]\n",
    "    len_bit = test_input['length'][i*189:(i+1)*189]\n",
    "    results.append(sess.run([g[\"preds\"]], feed_dict={g['x']: data_bit, g['seqlen'] : len_bit}))\n",
    "print(results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0][0][32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"output_LSTM.txt\", \"w\") as f:\n",
    "    f.write(\"id,realDonaldTrump,HillaryClinton\\n\")\n",
    "    #batch of 189\n",
    "    i = 0\n",
    "    print (len(results))\n",
    "    for n in range(len(results)):\n",
    "        print (len(results[n][0]))\n",
    "        for y in range(len(results[n][0])):\n",
    "            f.write(\"{},{:06f},{:06f}\\n\".format(i, results[n][0][y][0],results[n][0][y][1]))\n",
    "            i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
